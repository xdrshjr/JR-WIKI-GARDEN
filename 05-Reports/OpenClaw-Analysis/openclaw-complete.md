# OpenClaw：当AI助手摆脱浏览器，走进你的生活

> **TL;DR**: OpenClaw 是一个运行在你自己设备上的个人 AI 助手，它通过统一的 Gateway 控制平面连接你所有的通信渠道，让你的数据留在本地，让 AI 真正成为你数字生活的延伸。

---

## 浏览器的囚徒

让我们坦诚地面对一个尴尬的事实：过去两年，我们大多数人使用 AI 的方式，本质上和 2008 年使用 Facebook 没什么区别——打开浏览器，登录一个网站，在一个文本框里输入问题，然后等待服务器响应。我们像朝圣者一样每天访问 ChatGPT、Claude 或 Gemini，仿佛 AI 是一种需要"前往"才能获得的云服务，而不是一种可以"随身携带"的能力。

这种基于浏览器的交互模式，在尝鲜阶段无可厚非。但当你开始认真地用 AI 处理工作邮件、整理个人笔记、甚至讨论敏感的健康话题时，问题就变得棘手起来。你的对话历史存储在谁的服务器上？你的个人数据被用来训练什么模型？为什么每次切换设备都要重新登录？更重要的是，为什么 AI 不能主动在你需要的时候出现，而总是等着你打开浏览器去召唤它？

这些问题指向同一个核心矛盾：**我们需要的 AI 助手应该是 personal 的，但现有的解决方案都是 service 的**。我们希望 AI 了解我们的上下文、习惯、偏好，却又不愿意把最私密的数据交给远方的一台服务器。这个矛盾不解决，AI 就永远只是"高级搜索框"，而不是真正的个人助手。

## 本地优先：数据主权的回归

"Local-first" 不是技术复古主义，而是对数字主权的重新主张。想象这样一个场景：你正在手机上和朋友讨论周末聚会，想把讨论结果整理成待办事项。传统的云 AI 方案要求你把聊天记录发送给远方的服务器，由那里的模型处理后再返回结果。而本地优先的方案则是：你的手机直接运行 AI，处理本地数据，生成本地文件，没有任何数据离开你的设备。

OpenClaw 的设计哲学正是建立在这种理念之上。它不是一个"更小的云端 AI"，而是一个彻底重新架构的 AI 运行时。你的对话历史存储在本地文件系统中，你的技能配置是本地可读的 Markdown 文件，你的模型调用可以通过本地 Gateway 路由到本地或远程模型——选择权始终在你手中。

这种架构带来的好处是多方面的。**隐私方面**，敏感数据永远不会离开你的设备，除非你主动选择分享。**可靠性方面**，即使断网，本地缓存的模型和上下文依然可以让你继续工作。**可定制性方面**，你可以自由地修改系统提示词、添加自定义工具、甚至替换底层模型——没有平台锁定的束缚。

但本地优先并不意味着拒绝云端。OpenClaw 的巧妙之处在于它的**分层架构**：Gateway 作为本地控制平面，可以按需调用云端资源（如强大的 Claude Opus 或 GPT-4），但始终保持对数据的本地控制权。这就像是你拥有一辆可以在自家车库充电的电动车，但必要时也可以去超级充电站——选择权在你。

## 一个控制平面，无限可能

如果说本地优先解决了"数据在哪里"的问题，那么 Gateway 架构则解决了"AI 如何与我的世界交互"的问题。

传统 AI 应用的集成方式是点状的：一个 Slack 机器人、一个 Telegram 机器人、一个浏览器插件……每个渠道都是独立开发的，都有自己的上下文管理、权限控制和消息格式。OpenClaw 的做法是反直觉的：与其为每个渠道写一个适配器，不如建立一个**统一的控制平面**，让所有渠道都通过同一个 Gateway 与 AI 通信。

这个 Gateway 是一个 WebSocket 服务器，运行在你的本地设备上（默认端口 18789）。它同时扮演三个角色：

**作为渠道聚合器**，Gateway 维护着与 WhatsApp、Telegram、Slack、Discord、Signal、iMessage 等 12+ 通信渠道的连接。无论你从哪个渠道发送消息，Gateway 都会将其标准化为统一的消息格式，路由给 AI 处理，再将回复分发回原始渠道。

**作为设备控制中心**，Gateway 通过 Node 协议与 macOS、iOS、Android 设备配对，暴露本地能力：相机拍照、屏幕录制、位置获取、系统通知……这些原本需要单独开发 App 的功能，现在通过统一的 WebSocket 协议即可调用。

**作为会话管理器**，Gateway 维护着持久化的会话状态。你可以在 Telegram 上开始一个对话，在 WebChat 上继续，然后在 iMessage 上收到回复——整个过程中的上下文是连续且一致的。

这种架构的优雅之处在于**正交性**。添加一个新渠道只需要编写一个 Gateway 适配器，不需要改动 AI 核心逻辑。添加一个新设备能力只需要在 Node 协议中声明，所有渠道自动获得该能力。想要更换底层模型？修改配置文件即可，无需重写任何集成代码。

## 设计哲学的三重奏

OpenClaw 的设计可以用三个关键词概括：Local-first、Personal、Always-on。这三者相互支撑，构成了一个完整的个人 AI 体验。

**Local-first** 是技术基础。它确保了你的数据主权，提供了离线能力，降低了延迟，最重要的是——它让 AI 从"一个需要访问的网站"变成了"一个运行在设备上的进程"。这种转变看似微妙，却是从"使用 AI"到"与 AI 共生"的关键一步。

**Personal** 是体验目标。OpenClaw 不是为团队协作设计的，也不是为客服自动化设计的。它是一个单用户系统，所有的设计决策都围绕"如何让一个特定的人获得更好的 AI 体验"展开。从个性化的 AGENTS.md 配置文件，到基于个人笔记的上下文增强，再到跨设备的会话同步——一切都为了让 AI 更了解"你"。

**Always-on** 是交互范式。通过 Voice Wake 和 Talk Mode，OpenClaw 可以在后台持续监听语音唤醒词，实现类似 Siri 或 Alexa 的随时响应能力。但与那些云语音助手不同，你的语音数据在本地处理，只有经过确认的指令才会被发送到云端模型。这种设计在便利性和隐私之间取得了精妙的平衡。

这三重奏的合奏效果，是一种前所未有的 AI 体验：一个了解你、尊重你隐私、随时待命、又能在所有你使用的通信渠道中无缝出现的智能助手。它不是完美无缺的——本地运行意味着你需要管理自己的基础设施，配置模型 API，处理偶尔的网络问题。但对于那些愿意承担这些成本的用户来说，获得的回报是真正意义上的"个人"AI。

## 结语

OpenClaw 这个名字本身就充满了隐喻。爪（Claw）是龙虾的器官，用于感知、抓取和探索——这正是我们对个人 AI 助手的期待。而 "Open" 则代表了开源、开放和可扩展的哲学。

当 AI 摆脱浏览器的桎梏，真正走进我们的设备和生活，它才有可能从一个偶尔使用的工具，变成数字世界的自然延伸。OpenClaw 正在探索的，正是这样一条道路：不是把人类带到 AI 面前，而是让 AI 融入人类的生活场景之中。

这条路还很长。但至少，我们已经有了一个开始。

---

**延伸阅读**

- [OpenClaw Gateway 架构详解](./02-gateway-architecture.md)
- [Agent 生命周期与事件循环](./03-agent-loop.md)
- [多通道消息路由机制](./04-channel-routing.md)
- [本地优先的数据模型](./05-local-first-data.md)

---

*文档版本: 2026-02-03 | 作者: OpenClaw 技术文档团队*
# Gateway：一个WebSocket控制平面如何统治所有消息通道

> *一夫当关，万夫莫开。*
> 
> 这句古话用来形容OpenClaw的Gateway再合适不过。在一个充斥着碎片化消息协议的世界里，Gateway就像一位铁腕宰相，用一条WebSocket长连接统御着WhatsApp、Telegram、Slack、Discord、Signal、iMessage等各路诸侯。这不是简单的"适配器模式"，而是一场架构层面的中央集权运动。

---

![Gateway中央枢纽架构](./images/02-gateway-architecture.png)

*图1：Gateway作为中央控制枢纽，统一连接多个消息通道和客户端*

---

## 架构理念：为什么必须有一个"老大"

想象一下，如果没有Gateway，你的AI助手会是什么样子？WhatsApp来一个Baileys连接，Telegram来一个gramY实例，Discord再来一个discord.js客户端——每个通道都有自己的连接池、自己的事件循环、自己的重连逻辑。这就像一个外交官要同时学习十几种语言，每种语言还有不同的方言和礼仪。

**Gateway的解决之道很简单：你们都是弟弟。**

Gateway作为单一控制平面，默认绑定在`127.0.0.1:18789`，所有消息通道（通过各自的Provider）都向它汇报，所有客户端（CLI、macOS App、Web UI、iOS/Android Node）都向它请示。这种"星型拓扑"看似老派，实则是经过深思熟虑的选择——在复杂系统中，单一事实来源（Single Source of Truth）往往比去中心化更容易维护。

## WebSocket控制平面：为什么选择长连接

有人可能会问：为什么不直接用HTTP/2 Server-Send Events？或者gRPC？WebSocket不是上古技术吗？

答案藏在Gateway的双重身份里。它不仅是"消息转发器"，更是**会话管理器**和**能力协调器**。

WebSocket长连接就像是一条专线电话，而不是每次说话都要重新写信。当AI助手正在与用户进行多轮对话时，Gateway需要维护会话状态、管理Typing Indicator、处理流式响应的Chunked传输。更重要的是，Gateway要支持**双向实时通信**——不仅AI要给用户发消息，用户的手机Node也要向Gateway汇报摄像头截图或地理位置。

![WebSocket协议握手流程](./images/02-websocket-handshake.png)

*图2：WebSocket协议握手生命周期——从challenge到双向通信*

```
Client                    Gateway
  |                          |
  |---- req:connect -------->|
  |<------ res (hello-ok) ----|   ← 握手完成，通道建立
  |                          |
  |<------ event:presence ---|   ← 实时状态推送
  |<------ event:tick -------|   ← 心跳保活
  |------- req:agent ------->|   ← 用户发送消息
  |<------ event:agent ------|   ← 流式响应
```

这个协议设计有三个精妙之处：

1. **强制握手**：第一个帧必须是`connect`，携带角色声明（operator vs node）和设备身份。不符合规范的连接直接掐掉，不给攻击者试错机会。

2. **三元通信模型**：`req/res`用于请求-响应，`event`用于服务器推送。这种区分让客户端可以清晰地跟踪每个调用的生命周期，也便于实现幂等性控制（side-effecting方法需要idempotency key）。

3. **协议版本协商**：客户端发送`minProtocol`和`maxProtocol`，服务器决定实际使用的版本。这为未来协议演进留下了平滑升级的空间。

## 多通道统一接入：外交部的秘密

Gateway最耀眼的成就，是让十几个完全不同的消息协议在内部呈现出统一的抽象。

在Gateway看来，WhatsApp的Baileys、Telegram的gramY、Slack的Bolt、Discord的discord.js都只是**Provider**——它们负责将各自协议的细节翻译成Gateway能理解的通用事件。当一条WhatsApp消息进来时，Baileys Provider会将其转换为标准格式：`{type: "event", event: "chat", payload: {...}}`。Gateway不关心这条消息是从哪里来的，它只负责路由到正确的AI会话。

这种设计的妙处在于**关注点分离**。Provider只负责协议适配，Gateway只负责路由和状态管理，AI Agent只负责业务逻辑。如果你要添加一个新的消息通道（比如企业微信或飞书），只需要写一个新的Provider，无需改动Gateway核心。

但这里有一个微妙的权衡。Gateway坚持"单主机单实例"原则——每个主机上只有一个Gateway，也就只有一个WhatsApp会话。这不是技术限制，而是**产品哲学**：OpenClaw定位为"个人AI助手"，不是SaaS平台。一个人不需要同时在同一台机器上登录两个WhatsApp账号给自己发消息，对吧？

## 消息路由与事件流：邮局的智慧

当消息洪流涌入Gateway时，它是如何决定"这条消息该给谁处理"的？

答案是一套**多层路由体系**：

首先是**通道路由**。每个Provider接入时都会声明自己的身份（`whatsapp`、`telegram`、`slack`等），消息事件会带上通道标识。Gateway根据`channels.*.allowFrom`配置进行第一道过滤——只有白名单里的发送者才能触发AI响应。

其次是**会话路由**。这是Gateway最聪明的地方。它不是"一个通道对应一个AI"，而是"一个对话对应一个会话"。你在WhatsApp上与AI私聊是一个会话，在家庭群里@AI是另一个会话，在Telegram频道里召唤AI又是第三个会话。每个会话有独立的上下文、独立的工具权限、独立的记忆空间。

```
消息流入
    ↓
Provider 标准化
    ↓
Gateway 路由决策
    ↓
会话解析（谁 + 在哪 + 什么上下文）
    ↓
Agent 调度
    ↓
响应流出（原路返回）
```

最后是**Node路由**。当AI需要执行设备本地操作时（比如"帮我拍张照片"或"录一段屏幕"），Gateway不会亲自上阵——它会将`node.invoke`请求路由到拥有相应能力的Node。这个Node可以是你的iPhone、Android平板，或者另一台Mac。Gateway在这里扮演的是**服务注册中心**的角色，维护着一张能力地图：哪个设备支持摄像头、哪个设备支持地理位置、哪个设备正在线。

## 配对与安全模型：信任但要验证

既然Gateway是中央枢纽，它的安全就是整个系统的安全。OpenClaw采用了一套**零信任但友好**的模型。

所有WebSocket连接都需要携带**设备身份**（device identity）。新设备首次连接时，Gateway会发出`connect.challenge`，要求设备签名一个nonce。这个设计防止了重放攻击——即使有人截获了你的网络流量，也无法伪装成你的设备。

但安全不应该以牺牲用户体验为代价。对于**本地连接**（loopback地址或Tailscale内网），Gateway支持自动批准——毕竟，能物理访问你机器的人不需要黑客技术也能做坏事。对于**远程连接**，则必须显式配对批准（`openclaw pairing approve`），并获得一个设备Token用于后续连接。

这种分层安全模型既保护了远程访问场景，又不会让你在自家电脑上用CLI时每次都要掏出手机点确认。真正的安全是让用户愿意用的安全。

角色系统进一步加强了权限隔离：`operator`角色可以执行管理操作（查看状态、重启Gateway、审批配对请求），`node`角色只能声明自己的能力并响应invoke调用。一个设备可以同时拥有两个角色（比如macOS App既是操作客户端又是Node宿主），但权限检查是严格分开的。

## 结语：架构的哲学

Gateway的设计体现了OpenClaw团队对"个人AI助手"这一产品定位的深刻理解。

它不是企业级消息中间件，不需要支持百万并发；它是**你的**助手的基础设施，需要的是可靠性、可预测性和可控性。单一Gateway实例降低了运维复杂度，明确的协议契约让第三方集成成为可能，本地优先的安全模型保护了隐私。

在这个微服务盛行的时代，OpenClaw选择了一条看似"落后"的架构路线——单体守护进程、内存状态、本地绑定。但正是这种"不够酷"的选择，让个人用户可以在自己的笔记本上运行一个功能完整的AI助手，而不需要Kubernetes集群或AWS账号。

有时候，最好的架构不是最能扩展的，而是最能**服务于人**的。

---

*"Gateway是控制平面，但产品才是助理。"*

*—— OpenClaw 架构格言*
# Agent Loop：一场AI的独白与工具交响曲

> *"思考是最孤独的行为，直到它被表达出来。"*
> 
> 在OpenClaw的世界里，Agent Loop就是这场从孤独思考到外在表达的全过程。它不是简单的"输入-处理-输出"，而是一场精心编排的交响乐——有前奏、有变奏、有高潮，偶尔还有即兴的间奏（我们称之为工具调用）。

---

## 当一条消息闯入AI的世界

想象一下这个场景：你正在Telegram上和OpenClaw闲聊，突然问了一句"帮我查一下明天北京的天气，然后发邮件提醒我穿外套"。对AI来说，这短短一句话触发了一个复杂得令人咋舌的连锁反应。

在OpenClaw的架构中，这条消息的旅程始于**Gateway的chat事件**，经过Provider的标准化，变成一条结构化的消息进入Gateway的消息总线。但真正的魔法从`agent` RPC调用开始——这是整个Agent Loop的入口。

Gateway收到消息后不会直接扔给模型，而是先做三件事：

第一，**会话解析**。它要搞清楚"你是谁"、"我们在哪聊"、"之前聊过什么"。这决定了AI应该用什么样的上下文、什么样的工具权限、什么样的回复风格来回应你。

第二，**运行排队**。OpenClaw使用了一个巧妙的队列系统来确保同一会话中的消息按顺序处理。想象一下，如果你在Telegram上连续发了三条消息，你不会希望AI对第一条的回复穿插在对第三条的回复中间——那场面简直是一场灾难。

第三，**环境准备**。Gateway要加载Skills快照、准备Workspace、注入系统提示词。这就像演出前的舞台布置：灯光、音响、道具，一样都不能少。

## Pi Agent Core：循环的心脏

OpenClaw并没有从零开始造一个Agent运行时——它站在巨人的肩膀上，使用了**Pi Agent Core**作为底层引擎。这是一个专门为大模型应用设计的运行时，负责处理最复杂的部分：模型调用、流式响应、工具执行。

当`runEmbeddedPiAgent`被调用时，它首先会构建一个**Pi Session**——这是一个封装了所有运行时状态的上下文，包括模型配置、认证信息、工具集、历史消息等。然后，它会订阅Pi Core的事件流，开始一场持续数秒甚至数分钟的"对话"。

这场"对话"的美妙之处在于它的**双向性**。不是简单的"我问你答"，而是模型可以主动说"等等，我需要查一下资料"，然后调用工具，等待结果，再继续回答。这就是Agentic Loop的精髓：**模型不是被动响应者，而是主动的问题解决者**。

```
用户消息
    ↓
模型推理："用户想知道天气... 但我不知道天气"
    ↓
模型决定：调用 weather 工具
    ↓
工具执行：获取北京明天天气
    ↓
工具结果返回模型
    ↓
模型继续推理："现在我知道天气了，但用户还要发邮件..."
    ↓
模型决定：调用 send_email 工具
    ↓
工具执行：发送邮件
    ↓
模型生成最终回复："已查好天气，邮件已发送"
```

这个循环可以持续多轮。模型可以一次调用多个工具，可以在工具结果不满意时再次调用其他工具，甚至可以请求用户澄清（"你想让我发给哪个邮箱？"）。**这种能力让AI从"聊天机器人"升级成了"任务执行者"**。

## 流式响应：让用户感受AI的"思考过程"

早期的聊天AI有一个让人抓狂的体验：你发送消息后，要等待好几秒，然后突然蹦出一大段回复。你不知道AI是在思考，还是卡住了，还是已经死机了。

OpenClaw采用了**流式响应**（Streaming）来解决这个问题。从模型生成第一个token开始，文字就像打字机一样实时出现在你的屏幕上。你不仅能看到AI在"说话"，还能看到它在"思考"——当它决定调用工具时，你会看到工具名称和参数；当工具执行时，你会看到进度提示；当工具返回结果时，你会看到AI如何基于新信息继续推理。

这种透明性带来了两个好处：

**心理层面**，用户不会焦虑地等待。即使最终回复需要10秒才能生成，但用户在前2秒就能看到AI开始回应，这种"被听见"的感觉大大提升了体验。

**实用层面**，用户可以及时纠正。如果AI理解错了你的意图，在流式输出的前几个字你就能发现，可以立即打断重说，而不是等到整段话都说完。

OpenClaw的流式系统分为三个通道：

- **`assistant`通道**：AI生成的文字内容，实时推送到用户界面
- **`tool`通道**：工具调用事件（开始、参数、结果），用于展示AI在做什么
- **`lifecycle`通道**：运行状态事件（开始、结束、错误），用于系统控制和日志记录

这三个通道通过WebSocket同时推送给客户端，客户端可以根据需要决定如何展示。比如在CLI中，工具事件可能以灰色小字显示；在WebChat中，工具事件可能折叠成可展开的卡片；在macOS App中，工具事件可能触发通知音效。

## 工具调用：AI的"超能力"

如果说语言模型的推理能力是AI的"大脑"，那么工具调用就是它的"手脚"。OpenClaw提供了一套丰富的工具集，让AI可以真正与数字世界交互。

工具系统的核心设计原则是**Schema驱动**。每个工具都用TypeBox定义了严格的输入输出Schema，模型在调用时必须提供符合Schema的参数。这不仅保证了类型安全，也让模型在调用前就能"理解"这个工具能做什么、需要什么。

OpenClaw的工具分为几大类：

**信息获取类**：`web_search`、`web_fetch`、`read`——让AI可以查询互联网、读取文件、获取最新信息，弥补训练数据的时效性局限。

**行动执行类**：`exec`、`browser`、`message`——让AI可以执行代码、控制浏览器、发送消息，真正"动手"完成任务。

**设备交互类**：`nodes.camera_snap`、`nodes.screen_record`、`canvas.present`——通过Node系统与物理世界交互，拍照、录屏、展示可视化内容。

**会话管理类**：`sessions_list`、`sessions_send`、`sessions_spawn`——让AI可以管理多个会话，甚至创建子Agent并行处理任务。

每个工具调用都是一个完整的请求-响应周期。模型生成工具调用指令，Gateway验证参数，执行工具，获取结果，将结果格式化为消息追加到对话历史中，然后让模型继续生成。这个过程对用户是透明的——你只看到AI在"思考"，然后"行动"，然后给出结果。

## Session管理：记忆的艺术

Agent Loop之所以能够持续多轮对话而不失上下文，关键在于**Session管理**。在OpenClaw中，Session不仅仅是一堆消息的集合，它是一个完整的状态容器。

每个Session有唯一的key（通常是`agent:main:main`这样的格式），包含：

- **消息历史**：所有用户和AI的对话记录，用于上下文理解
- **工具结果**：之前工具调用的结果缓存，避免重复执行
- **系统配置**：模型选择、思考级别、工具白名单等运行时参数
- **持久化存储**：可以保存到磁盘，下次启动时恢复对话

Session管理最棘手的问题是**上下文窗口限制**。大模型的上下文窗口虽然越来越大（Claude 3.5 Sonnet有200k token），但终究是有限的。当对话历史接近上限时，OpenClaw会触发**压缩**（Compaction）机制。

压缩不是简单的"删掉前面的消息"，而是让模型生成一份**对话摘要**，用几百字的摘要替代几千字的原始对话。这份摘要保留了关键信息（用户 preferences、已确认的事实、待办事项），丢弃了冗余内容（客套话、重复表达、临时性内容）。压缩后的Session可以继续使用，而对用户来说，AI依然"记得"之前的对话——只是不记得每一个字了。

## 超时、错误与优雅降级

任何复杂的系统都会出错，Agent Loop也不例外。OpenClaw设计了一套完整的**错误处理机制**来确保即使在最坏的情况下，用户也能得到体面的体验。

**超时处理**：每个Agent运行有默认600秒的超时限制。如果模型思考太久（比如陷入循环或处理超大文件），Gateway会强制中断并返回超时错误。这比无限等待要好得多——至少用户知道发生了什么。

**工具错误**：当工具执行失败时（比如网络不通、文件不存在、权限不足），错误信息会被捕获并返回给模型。模型可以根据错误信息决定是重试、换用其他工具、还是向用户解释问题。这种**错误反馈循环**让AI有了基本的故障恢复能力。

**优雅降级**：如果某个Skill加载失败、某个Node离线、或者某个模型API不可用，OpenClaw不会直接崩溃。它会标记这些资源为不可用，继续用剩余的资源完成任务。这种**韧性设计**让系统能够在部分失效的情况下继续服务。

## 结语：循环的意义

Agent Loop不仅仅是一个技术实现，它代表了一种新的计算范式：**从命令式到意图式**。

在传统的软件使用中，你需要精确地告诉计算机每一步怎么做（"打开浏览器，访问天气网站，输入城市名，读取温度"）。而在Agent Loop中，你只需要表达意图（"告诉我明天天气"），AI会自己 figuring out 如何完成。

这种转变的深层意义在于**认知负荷的转移**。人类不擅长记忆复杂的操作步骤，但擅长表达目标和意图。Agent Loop让计算机承担了"如何做到"的负担，让人类专注于"想要什么"。

OpenClaw的Agent Loop实现不是最完美的——它有时会出错，有时会误解，有时会在工具调用上浪费token。但它代表了正确的方向：**让AI成为主动的助手，而不是被动的工具**。

当这场从输入到输出的循环完成时，你收到的不仅仅是一个答案，而是一次完整的协作体验。这就是Agent Loop的魔力。

---

---

![Agent循环架构图](./images/03-agent-loop-flow.png)

*图1：Agent Loop循环流程图——展示从输入处理到工具调用再到响应生成的完整循环*

![AI工具调用流程](./images/03-tool-calling.png)

*图2：AI工具调用流程图——展示AI Agent与各类工具（搜索、文件、终端、相机、消息）的交互*

---

**延伸阅读**

- [OpenClaw Gateway 架构详解](./02-gateway.md)
- [Skills与Nodes：开放生态](./04-ecosystem.md)
- [技术栈选型](./05-tech-stack.md)

---

*文档版本: 2026-02-03 | 作者: OpenClaw 技术文档团队*
# Skills与Nodes：开放生态的无限可能

> "如果你不能让AI学会新技能，那它不过是一个会聊天的搜索引擎；如果你不能让设备成为AI的延伸，那它只是一个孤岛上的智能。"

OpenClaw的设计理念从一开始就拒绝了"大而全"的封闭架构。我们坚信，真正强大的AI系统应该是开放的、可扩展的、像生物一样能够不断进化的。在这篇文章中，我们将深入探讨OpenClaw的两大扩展支柱——Skills系统和Nodes系统，以及它们如何共同构建起一个充满活力的开放生态。

## Skills：让AI学会新技能的秘诀

想象一下，你雇佣了一位超级聪明的助理，但她刚入职时只会打字。你可以教她使用Excel、写邮件、甚至操作复杂的软件——只要给她一本"使用手册"。在OpenClaw中，Skills就是这本使用手册。

OpenClaw采用了**AgentSkills规范**，这是一种业界通用的技能描述格式。每个Skill本质上就是一个文件夹，里面有一个`SKILL.md`文件，用简洁的YAML frontmatter描述这个技能是做什么的，后面跟着详细的使用说明。这种设计妙在何处？它把"教AI使用工具"这个原本需要编程的工作，变成了一种近乎自然语言的描述任务。

但OpenClaw的Skill系统真正厉害的地方在于它的**分层加载机制**和**智能门控系统**。

### 三层架构：灵活与稳定的平衡术

OpenClaw从三个地方加载Skills：

1. **Bundled Skills** —— 随系统安装的基础技能，就像手机预装的应用
2. **Managed Skills** —— 存放在`~/.openclaw/skills`的用户级技能，所有Agent共享
3. **Workspace Skills** —— 特定工作空间的技能，优先级最高

这种设计的聪明之处在于它解决了"稳定性vs灵活性"这个永恒的矛盾。你想试试最新的实验性功能？丢到Workspace里，不会影响其他项目。你有某个团队通用的工具集？放到Managed目录，大家都能用。而Bundled技能则保证了开箱即用的体验。

当同名技能冲突时，OpenClaw遵循 Workspace → Managed → Bundled 的优先级顺序。这种"就近原则"符合直觉：离你当前工作最近的配置应该拥有最高话语权。

### Gating：条件加载的艺术

如果说三层架构解决的是"在哪里"的问题，那Gating系统解决的就是"什么时候"的问题。

OpenClaw允许Skill声明自己的**准入条件**：

```yaml
metadata:
  openclaw:
    requires:
      bins: ["uv", "docker"]
      env: ["GEMINI_API_KEY"]
      config: ["browser.enabled"]
```

这段metadata的意思是：只有当系统安装了uv和docker、配置了GEMINI_API_KEY、并且在配置中启用了browser功能时，这个Skill才会被加载。这种声明式的依赖管理让Skill系统有了"自我意识"——它知道自己在什么环境下能工作，在什么环境下应该保持沉默。

这种设计带来的好处是巨大的。首先，**错误预防**：你不会在没装Docker的机器上看到一个需要Docker的技能，然后运行时报错。其次，**界面整洁**：用户的技能列表里只显示当前能用的技能，不会被一堆"灰色不可用"的条目污染视线。最重要的是，**可移植性**：同一个OpenClaw配置，在Mac上可能加载一套技能，在Linux服务器上加载另一套，完全根据环境自适应。

### ClawHub：技能的中央火车站

有了技能格式的标准和加载机制，下一个问题就是：技能从哪里来？

ClawHub是OpenClaw的官方技能仓库，但它的设计理念非常"Unix哲学"：只做一件事，把它做好。ClawHub不负责运行技能，它只是技能的发现、安装和同步中心。你可以用一行命令安装技能：`clawhub install <skill-slug>`，也可以用`clawhub sync`备份你的技能配置。

这种设计把"技能市场"和"技能运行时"解耦，让技能生态可以独立发展。任何人都可以创建自己的技能仓库，只要遵循AgentSkills规范，OpenClaw就能加载它。

## Nodes：当设备成为能力的延伸

如果说Skills是"软扩展"，那Nodes就是"硬扩展"。OpenClaw的Node系统让我们看到了一个迷人的可能性：把你的手机、平板、甚至另一台电脑，变成AI的感知器官和执行肢体。

Node的核心架构简洁而强大：任何设备只要能通过WebSocket连接到Gateway，并声明`role: "node"`，就能成为OpenClaw的能力节点。这个设计的高明之处在于它的**协议无关性**——不管是iOS、Android、macOS还是headless Linux，只要实现了Node协议，就能被OpenClaw统一调度。

### 能力发现：让设备自己说话

传统的设备集成通常需要预先配置驱动、写适配代码。OpenClaw的Node系统采用了一种更优雅的方式：**能力发现**。

当一个Node连接时，它会广播自己支持的命令集。比如一个iPhone可能会说："我支持camera.snap（拍照）、camera.clip（录像）、canvas.present（显示内容）、location.get（获取位置）"。Gateway收到这些信息后，就会把这些能力纳入考虑范围。当AI需要拍照时，它会知道"哦，我可以调用那个iPhone Node的camera.snap命令"。

这种**自描述架构**的美妙之处在于扩展性。新加入的设备不需要修改Gateway代码，只要实现自己的命令集并正确宣告，就能立即被系统使用。这就像USB的即插即用，但发生在软件能力层面。

### 远程执行：打破物理边界

Node系统最实用的场景之一是**远程执行**。假设你的Gateway运行在一台Linux服务器上，但你需要在Mac上执行某些命令。传统做法是SSH过去，但OpenClaw提供了一种更集成的方式：把Mac配置为一个Node Host。

通过在Mac上运行`openclaw node run`，这台Mac就变成了一个能力节点。Gateway可以将exec调用转发到这台Mac上执行，而且完全遵循Gateway的安全策略（allowlist、审批流程等）。对AI来说，这一切都是透明的——它只是在调用一个exec工具，至于实际执行是在本地还是远程的Mac上，它不需要关心。

这种架构打开了无数可能性：你可以让家里的Mac负责处理图像、办公室的PC负责运行代码、手机负责采集现场信息——所有设备在一个统一的AI调度下协同工作。

### Canvas：AI的可视化思维面板

Node系统中最具未来感的功能是Canvas。简单来说，Canvas就是一个由AI控制的浏览器窗口——但这个描述实在太过苍白，无法传达它的革命性。

想象这样一个场景：AI正在帮你分析一张复杂的图表。它可以把这张图表显示在Canvas上，然后用红色圈出关键区域，在旁边添加文字注释，甚至生成一个交互式的小工具让你调整参数。这一切都是通过标准的Web技术（HTML/CSS/JS）实现的。

Canvas采用`openclaw-canvas://`自定义URL scheme，内容存储在本地文件系统中。AI可以通过`canvas.navigate`加载页面，通过`canvas.eval`执行JavaScript，通过`canvas.snapshot`截图。这意味着AI有了一个**持久的可视化工作空间**，可以用来展示中间结果、收集用户输入、或者只是给你一个直观的进度反馈。

更有趣的是A2UI（Agent-to-User Interface）协议的支持。AI可以通过结构化的JSONL消息在Canvas上构建动态UI，就像有了一个随时可以重绘的画布。这不仅仅是"显示信息"，而是开启了**AI驱动的交互式设计**的可能性。

## 安全：开放但不放任

扩展性和安全性往往是鱼与熊掌。OpenClaw的解决方案是**分层防御**。

对于Skills，安全模型包括：
- **源码可见**：Skill本质上是Markdown文件，用户可以（也应该）在安装前阅读它
- **条件门控**：通过requires.bins/env/config限制技能的激活条件
- **配置隔离**：通过entries配置可以单独禁用某个技能或限制它的环境变量

对于Nodes，安全模型更加严格：
- **设备配对**：每个Node连接都需要显式批准（`openclaw nodes approve`）
- **命令白名单**：Node Host上的exec调用受`exec-approvals.json`控制，可以精确控制允许执行的命令
- **权限映射**：Node需要声明自己的权限状态（camera、location等），Gateway会检查这些权限

这种设计体现了"最小权限原则"：AI只能使用被明确授权的Skills，只能调用已批准Node上的允许命令。开放生态不意味着放任自流，而是在可控的边界内给予最大的自由。

## 结语：生态的力量

OpenClaw的Skills和Nodes系统共同构建了一个前所未有的开放架构。在这个架构中，AI不再是运行在单一服务器上的孤立程序，而是一个可以不断学习和扩展的智能体，能够调动周围所有的设备和能力为自己所用。

这种设计哲学可以概括为：**中心化的智能，去中心化的能力**。Gateway负责协调和决策，但具体的执行能力分布在Skills和Nodes之中。这不仅让系统更加灵活，也创造了一个可持续进化的生态——今天某个开发者发布的新Skill，明天就能被成千上万的OpenClaw用户使用；你刚买的智能设备，只要实现了Node协议，立刻就能成为AI的"新器官"。

在技术史上，那些真正改变世界的平台都有一个共同特点：它们不是封闭的产品，而是开放的生态。OpenClaw正走在这样的道路上。

![Skills生态概念图](./images/04-skills-ecosystem.png)
*图1：OpenClaw Skills分层架构示意图。Workspace层提供项目级定制，Managed层共享用户级工具，Bundled层保证基础能力，三层协同构建完整的技能生态。*

![Node网络概念图](./images/04-node-network.png)
*图2：Node分布式能力网络。各类设备通过WebSocket连接到中央Gateway，暴露各自的独特能力（相机、位置、屏幕、计算资源），形成AI的分布式感知-执行网络。*
# 技术栈选型：为什么我们选择这些工具？

> "选择技术栈就像选择人生伴侣——没有完美的，只有最适合的。" —— 某位在凌晨三点还在调试依赖冲突的工程师

构建一个Agent网关系统，技术栈的选择直接决定了你能走多远。本文将坦诚地分享OpenClaw团队在关键决策点上的思考过程，包括那些"早知道就选另一个"的后悔时刻。

## TypeScript + Node.js：被误解的黄金搭档

让我们直面争议：为什么不是Python？毕竟，AI生态几乎被Python统治。

答案很简单：**我们不是在写模型训练代码，我们在写基础设施。**

当Agent需要同时处理WhatsApp的WebSocket连接、Telegram的HTTP轮询、以及本地浏览器的CDP调试协议时，Node.js的事件循环比Python的asyncio要成熟得多。更重要的是，我们面对的是大量I/O密集型操作——消息收发、网络请求、文件系统操作——这正是Node.js的舒适区。

TypeScript则给了我们静态类型检查的安全感，又不牺牲JavaScript的灵活性。我们的`tsconfig.json`配置了严格的类型检查，但一旦涉及到与各种第三方SDK的交互，我们又能在必要时优雅地退回到`any`。这种"严格但务实"的态度贯穿整个项目。

当然，代价也是真实的。Node.js的单线程模型意味着一个同步的CPU密集型操作就能阻塞整个事件循环。我们的解决方案？把那些真正耗时的任务（比如PDF解析、图片处理）扔到Docker沙箱里，让它们在隔离环境中慢慢折腾，主进程继续响应消息。

## WebSocket：实时通信的「老派浪漫」

在Server-Sent Events、HTTP/2推送、gRPC流等众多选择面前，我们选择了最「老派」的WebSocket。为什么？

**因为可靠。**

OpenClaw的核心是一个Gateway服务，它需要同时与多个客户端保持长连接：macOS应用、Web界面、命令行工具，以及运行在各种设备上的Node代理。WebSocket的简单性在这里是优势——它就是一个双向通信管道，没有gRPC的复杂proto定义，没有SSE的单向限制。

我们基于`ws`库构建了一套完整的客户端-服务器协议。每个消息帧都有明确的类型：`req`（请求）、`res`（响应）、`event`（服务器推送）。连接建立后，客户端发送`connect`请求完成握手，之后就可以调用各种方法（如`send`、`poll`、`agent`）并订阅事件（如`presence`、`tick`）。

这套协议的一个设计亮点是**心跳检测**。Gateway每30秒发送一个`tick`事件，客户端如果在两倍间隔内没有收到，就认为连接已死，主动断开并重连。这种"猜疑链"设计比TCP的keepalive更可靠，因为它检测的是应用层的健康状态，而不仅仅是网络连通性。

## TypeBox：类型系统的「单一真相源」

如果你维护过大型TypeScript项目，你一定经历过这种痛苦：类型定义、运行时验证、API文档，三者各自为政，改了一处忘改另一处。

TypeBox解决了这个问题。

我们用TypeBox定义Gateway协议的所有schema——从`ConnectParams`到`ChatMessage`，从请求参数到响应结构。这些schema同时服务于三个目的：

1. **编译时类型检查**：TypeScript从schema推断出类型，确保代码的类型安全
2. **运行时验证**：通过AJV编译schema，验证每个进出Gateway的消息
3. **跨语言生成**：自动生成JSON Schema和Swift模型，供macOS客户端使用

举个例子，当我们需要添加一个新的API方法时，只需要在`src/gateway/protocol/schema.ts`中添加TypeBox定义，然后运行`pnpm protocol:check`，一切就自动就绪了。没有手写验证代码，没有手动同步文档，没有"类型和实现对不上"的bug。

这种"写一次，到处用"的理念，是我们对抗技术债务的利器。

## Pi Agent Core：站在巨人的肩膀上

Agent运行时是整个系统的心脏。我们没有从零开始造轮子，而是选择了`@mariozechner/pi-agent-core`作为基础。

这个选择背后是务实的考量：Agent运行时需要处理工具调用、对话管理、上下文窗口、错误恢复等复杂逻辑，这些都是可以 commoditized 的通用能力。我们的核心竞争力在于**连接**——把Agent接入各种消息平台——而不是Agent本身。

Pi Agent Core提供了一套清晰的扩展点，让我们可以注入自定义的工具提供者、LLM客户端、和对话存储。我们的沙箱系统、浏览器控制、节点配对等功能，都是作为插件接入这个核心。

当然，依赖第三方核心也有风险。如果有一天Pi Agent Core的更新方向与我们的需求冲突，我们可能需要fork或者替换。但在项目的这个阶段，"借用"比"拥有"更明智。

## 通道SDK：拥抱生态，保持灵活

OpenClaw支持多种消息通道，每种都有官方的Node.js SDK。我们的选型策略是：**能用官方SDK就用官方SDK，除非它实在太烂。**

- **WhatsApp**：使用`@whiskeysockets/baileys`。这是一个社区维护的库，基于WhatsApp Web协议。它不是官方SDK，但是开源社区最好的选择。代价是WhatsApp可以随时更改协议，让我们 scrambling。

- **Telegram**：使用`grammy`。这是一个设计精良、文档完善的框架，支持Webhook和轮询两种模式，还有丰富的插件生态。`@grammyjs/runner`和`@grammyjs/transformer-throttler`让我们的消息发送既高效又不会触发速率限制。

- **Slack**：使用`@slack/bolt`。Slack的官方SDK，支持Socket Mode（WebSocket）和HTTP模式。Socket Mode特别适合我们的Gateway架构——不需要公网URL，只需要一个WebSocket连接。

- **Line**：使用`@line/bot-sdk`。Line的官方SDK，简单易用，但功能相对基础。

- **Discord**：使用`@buape/carbon`。这是一个相对较新的库，但我们选择它是因为它对Discord的新特性支持更好，而且API设计更符合现代TypeScript风格。

每个SDK都有自己的 quirks 和 rate limits。我们的Gateway层做了统一抽象，让上层代码不需要关心"这条消息是发给Telegram还是WhatsApp"。这种解耦让我们可以轻松添加新通道，或者替换现有实现。

## 安全与沙箱：不信任任何人

Agent系统天然具有危险性——它可能执行代码、访问文件、与外网通信。我们的安全设计基于一个原则：**最小权限 + 深度防御**。

**沙箱层**使用Docker容器隔离Agent执行环境。默认配置下，容器运行在只读root文件系统上，丢弃了所有Linux capabilities（除了绝对必要的），有严格的CPU、内存、PID限制。seccomp和AppArmor配置文件进一步限制了系统调用。

**审计层**记录了所有工具调用和外部访问。每个`exec`、`read`、`write`操作都会被记录，包括调用参数、执行结果、耗时。这些日志不仅用于安全审查，也用于调试和性能分析。

**策略层**允许为每个Agent配置不同的权限。有些Agent只能访问特定目录，有些可以执行任意命令，有些完全不能访问网络。这些策略在运行时动态解析，合并全局配置和Agent特定的覆盖。

最有趣的设计是**工具策略（Tool Policy）**。我们不仅限制Agent能做什么，还限制它*认为*自己能做什么。一个在沙箱中运行的Agent，它的工具列表里不会包含`browser`或`exec`，即使这些工具在全局可用。这种"能力隐藏"防止了Agent产生不切实际的期望，也简化了错误处理。

## 总结：没有银弹，只有权衡

回顾这些技术选择，没有一个是"完美"的。TypeScript给了我们类型安全，但也带来了构建复杂性。Docker沙箱提供了隔离，但也增加了资源开销。Pi Agent Core加速了开发，但也引入了外部依赖。

但这就是工程的本质——在约束条件下做出最优决策，并准备好在未来条件变化时重新评估。

OpenClaw的技术栈不是刻在石头上的。如果明天出现了一个更好的Agent运行时，或者Rust的异步生态突然变得对Node.js开发者友好了，我们会毫不犹豫地考虑迁移。但在当下，这套栈让我们能够快速迭代、可靠交付、并保持对代码的掌控感。

毕竟，技术栈是手段，不是目的。我们的目标是让Agent能够无缝地与人交流——无论他们使用什么平台。只要工具能帮助实现这个目标，它就是好工具。
